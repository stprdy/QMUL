{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BZ0h9pQ8ZKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278540b9-d73b-4bb9-d8fc-cf2284a6b8e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import ToTensor, Normalize, Compose\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/My Drive/100/'\n",
        "os.chdir(dataset_path)"
      ],
      "metadata": {
        "id": "4SOB-oQu_47M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf cifar-10-python.tar.gz"
      ],
      "metadata": {
        "id": "lStFhDAUEL_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7c0a2d-71f5-492a-c2ec-c765d1fb2c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-batches-py/\n",
            "cifar-10-batches-py/data_batch_4\n",
            "cifar-10-batches-py/readme.html\n",
            "cifar-10-batches-py/test_batch\n",
            "cifar-10-batches-py/data_batch_3\n",
            "cifar-10-batches-py/batches.meta\n",
            "cifar-10-batches-py/data_batch_2\n",
            "cifar-10-batches-py/data_batch_5\n",
            "cifar-10-batches-py/data_batch_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('.')"
      ],
      "metadata": {
        "id": "E__a8bsCETlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3045ade8-147a-4bae-b501-4c72becac531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cifar-10-python.tar.gz', 'cifar-10-batches-py']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unpickle(file):\n",
        "    with open(f'cifar-10-batches-py/{file}', 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict\n"
      ],
      "metadata": {
        "id": "FlT3XYD5ALiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "# Load and append all training batches\n",
        "for i in range(1, 6):\n",
        "    batch = unpickle(f'data_batch_{i}')\n",
        "    train_data.append(batch[b'data'])\n",
        "    train_labels += batch[b'labels']\n",
        "\n",
        "# Convert lists to numpy arrays for convenience\n",
        "train_data = np.vstack(train_data).reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "# Load the test batch\n",
        "test_batch = unpickle('test_batch')\n",
        "test_data = test_batch[b'data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
        "test_labels = np.array(test_batch[b'labels'])"
      ],
      "metadata": {
        "id": "p8kLoBZDAZYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Training labels shape: {train_labels.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "print(f\"Test labels shape: {test_labels.shape}\")"
      ],
      "metadata": {
        "id": "oqfPdJdzFW5W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c445c136-ee3a-418b-ee6b-a7c46b3ee872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (50000, 32, 32, 3)\n",
            "Training labels shape: (50000,)\n",
            "Test data shape: (10000, 32, 32, 3)\n",
            "Test labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader Task 1"
      ],
      "metadata": {
        "id": "-caUY0lnGTAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_tensor = torch.tensor(train_data.transpose((0, 3, 1, 2)), dtype=torch.float) / 255.0\n",
        "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
        "test_data_tensor = torch.tensor(test_data.transpose((0, 3, 1, 2)), dtype=torch.float) / 255.0\n",
        "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)\n",
        "\n",
        "train_data_tensor = (train_data_tensor - 0.5) / 0.5\n",
        "test_data_tensor = (test_data_tensor - 0.5) / 0.5\n",
        "\n",
        "train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n",
        "test_dataset = TensorDataset(test_data_tensor, test_labels_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "ouvd-m33GdOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the first batch from the train_loader\n",
        "first_batch_inputs, first_batch_labels = next(iter(train_loader))\n",
        "print(f\"Shape of the inputs in the first batch: {first_batch_inputs.shape}\")\n",
        "# Expected output: Shape of the inputs in the first batch: torch.Size([64, 3, 32, 32])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4d98aHIpk5x",
        "outputId": "51123c3b-2908-4333-e222-4149aa1d79ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the inputs in the first batch: torch.Size([64, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"Batch images shape: {images.shape}\")\n",
        "print(f\"Batch labels shape: {labels.shape}\")\n",
        "\n",
        "# Visualize the first image in the batch\n",
        "plt.figure(figsize=(2, 2))\n",
        "plt.imshow(images[0].permute(1, 2, 0) * 0.5 + 0.5)  # Unnormalize\n",
        "plt.title(f\"Label: {labels[0]}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xGiUdmEnJJBk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "298bd4c0-26a0-40a5-97a5-108d9cc51e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch images shape: torch.Size([64, 3, 32, 32])\n",
            "Batch labels shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # version 2\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class ImprovedIntermediateBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(ImprovedIntermediateBlock, self).__init__()\n",
        "#         self.convs = nn.ModuleList([\n",
        "#             nn.Sequential(\n",
        "#                 nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "#                 nn.BatchNorm2d(64),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Dropout2d(0.2),\n",
        "#             ),\n",
        "#             nn.Sequential(\n",
        "#                 nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "#                 nn.BatchNorm2d(64),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Dropout2d(0.2),\n",
        "#             ),\n",
        "#             nn.Sequential(\n",
        "#                 nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
        "#                 nn.BatchNorm2d(out_channels),\n",
        "#                 nn.ReLU(),\n",
        "#                 nn.Dropout2d(0.2),\n",
        "#             )\n",
        "#         ])\n",
        "#         self.pool = nn.AdaptiveAvgPool2d((8, 8))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         for conv in self.convs:\n",
        "#             x = conv(x)\n",
        "#         x = self.pool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# class EnhancedOutputBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, num_classes):\n",
        "#         super(EnhancedOutputBlock, self).__init__()\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc1 = nn.Linear(in_channels, in_channels // 2)\n",
        "#         self.fc2 = nn.Linear(in_channels // 2, num_classes)\n",
        "#         self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.avgpool(x)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n",
        "# class CIFAR10Classifier(nn.Module):\n",
        "#     def __init__(self, num_blocks=2, num_classes=10):\n",
        "#         super(CIFAR10Classifier, self).__init__()\n",
        "#         self.blocks = nn.ModuleList()\n",
        "#         in_channels = 3\n",
        "#         out_channels = 64\n",
        "#         for i in range(num_blocks):\n",
        "#             self.blocks.append(ImprovedIntermediateBlock(in_channels, out_channels))\n",
        "#             in_channels = out_channels\n",
        "#         self.output_block = EnhancedOutputBlock(out_channels, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         for block in self.blocks:\n",
        "#             x = block(x)\n",
        "#         x = self.output_block(x)\n",
        "#         return x\n",
        "\n",
        "# model = CIFAR10Classifier()\n",
        "# print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7gYVigiJHfv",
        "outputId": "76532afc-6fe4-4cab-986a-4ce519dcb111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR10Classifier(\n",
            "  (blocks): ModuleList(\n",
            "    (0): ImprovedIntermediateBlock(\n",
            "      (convs): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Dropout2d(p=0.2, inplace=False)\n",
            "        )\n",
            "        (1-2): 2 x Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Dropout2d(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
            "      (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
            "    )\n",
            "    (1): ImprovedIntermediateBlock(\n",
            "      (convs): ModuleList(\n",
            "        (0-2): 3 x Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Dropout2d(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
            "      (fc): Linear(in_features=4096, out_features=64, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (output_block): EnhancedOutputBlock(\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Task 2"
      ],
      "metadata": {
        "id": "f04KWk9QWOHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedIntermediateBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ImprovedIntermediateBlock, self).__init__()\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(0.2),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(0.2),\n",
        "            ),\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout2d(0.2),\n",
        "            )\n",
        "        ])\n",
        "        self.pool = nn.AdaptiveAvgPool2d((8, 8))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x)\n",
        "        x = self.pool(x)\n",
        "        # Note: Removed flattening and self.fc to preserve 4D output shape\n",
        "        return x\n",
        "\n",
        "class EnhancedOutputBlock(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(EnhancedOutputBlock, self).__init__()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(in_channels * 1 * 1, in_channels // 2)\n",
        "        self.fc2 = nn.Linear(in_channels // 2, num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)  # Flattening is appropriate here for FC layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class CIFAR10Classifier(nn.Module):\n",
        "    def __init__(self, num_blocks=2, num_classes=10):\n",
        "        super(CIFAR10Classifier, self).__init__()\n",
        "        self.blocks = nn.ModuleList()\n",
        "        in_channels = 3\n",
        "        out_channels = 64  # Adjust based on the architecture's requirement\n",
        "        for i in range(num_blocks):\n",
        "            self.blocks.append(ImprovedIntermediateBlock(in_channels, out_channels))\n",
        "            in_channels = out_channels\n",
        "        self.output_block = EnhancedOutputBlock(out_channels, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        x = self.output_block(x)\n",
        "        return x\n",
        "\n",
        "# Model initialization for demonstration\n",
        "modelb = CIFAR10Classifier()\n",
        "print(modelb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXhZlozjiYUi",
        "outputId": "b1d8c111-6abc-4452-dc84-8057ee0b5613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR10Classifier(\n",
            "  (blocks): ModuleList(\n",
            "    (0): ImprovedIntermediateBlock(\n",
            "      (convs): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Dropout2d(p=0.2, inplace=False)\n",
            "        )\n",
            "        (1-2): 2 x Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Dropout2d(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
            "    )\n",
            "    (1): ImprovedIntermediateBlock(\n",
            "      (convs): ModuleList(\n",
            "        (0-2): 3 x Sequential(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "          (3): Dropout2d(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (pool): AdaptiveAvgPool2d(output_size=(8, 8))\n",
            "    )\n",
            "  )\n",
            "  (output_block): EnhancedOutputBlock(\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (fc2): Linear(in_features=32, out_features=10, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Task 3"
      ],
      "metadata": {
        "id": "h0xhXFE4WS5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming CIFAR10Classifier is the class name for Version 2 of the model\n",
        "modelb = CIFAR10Classifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(modelb.parameters(), lr=0.001)\n",
        "\n",
        "# CIFAR-10 Data Loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 10  # Adjust as per requirement\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = modelb(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImF0_94hgClJ",
        "outputId": "d3c78083-0ade-4f15-c140-0a025eb856a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 63992678.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 1.9201718475812537\n",
            "Epoch 2, Loss: 1.723445228908373\n",
            "Epoch 3, Loss: 1.6384051207386319\n",
            "Epoch 4, Loss: 1.552598842726949\n",
            "Epoch 5, Loss: 1.487273252071322\n",
            "Epoch 6, Loss: 1.4366286993026733\n",
            "Epoch 7, Loss: 1.380320988347768\n",
            "Epoch 8, Loss: 1.3379279149462804\n",
            "Epoch 9, Loss: 1.2834130206223948\n",
            "Epoch 10, Loss: 1.2516043393508247\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelb.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Deactivate gradients for evaluation\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = modelb(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy} %')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCcoQWZpQOE_",
        "outputId": "5e121390-26cb-42db-f793-b826afb69510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the 10000 test images: 66.85 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Task 4\n"
      ],
      "metadata": {
        "id": "m8vU0--QWXVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming CIFAR10Classifier is already defined and ready to be used\n",
        "\n",
        "# Define your CIFAR10Classifier model\n",
        "modelb = CIFAR10Classifier().to(device)\n",
        "\n",
        "# Criterion (Loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer - SGD with learning rate = 0.01 and weight decay = 0.0005\n",
        "optimizer = optim.SGD(modelb.parameters(), lr=0.01, weight_decay=0.0005)\n",
        "\n",
        "# CIFAR-10 Data Loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 30  # You might adjust this based on observation\n",
        "for epoch in range(num_epochs):\n",
        "    modelb.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = modelb(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n",
        "\n",
        "# Don't forget to evaluate your model on the test set after training\n",
        "modelb.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Gradient computation is not needed for evaluation\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = modelb(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKRlyPp_QXfB",
        "outputId": "7e695065-afeb-417e-9289-26a117e02d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 2.2499043228071365\n",
            "Epoch 2, Loss: 2.0759009603039384\n",
            "Epoch 3, Loss: 1.9689246632558914\n",
            "Epoch 4, Loss: 1.901074612689445\n",
            "Epoch 5, Loss: 1.8472076241317612\n",
            "Epoch 6, Loss: 1.8003965338782582\n",
            "Epoch 7, Loss: 1.7622349650963494\n",
            "Epoch 8, Loss: 1.7361485461139923\n",
            "Epoch 9, Loss: 1.7113205109106\n",
            "Epoch 10, Loss: 1.6816463346981332\n",
            "Epoch 11, Loss: 1.6568673065556285\n",
            "Epoch 12, Loss: 1.6290464712225872\n",
            "Epoch 13, Loss: 1.611982100302606\n",
            "Epoch 14, Loss: 1.5897108513071103\n",
            "Epoch 15, Loss: 1.572034317056846\n",
            "Epoch 16, Loss: 1.5512201484206998\n",
            "Epoch 17, Loss: 1.5318830426391739\n",
            "Epoch 18, Loss: 1.5172591369475246\n",
            "Epoch 19, Loss: 1.4942419678353898\n",
            "Epoch 20, Loss: 1.4822416895490778\n",
            "Epoch 21, Loss: 1.465499476551095\n",
            "Epoch 22, Loss: 1.4487827263219888\n",
            "Epoch 23, Loss: 1.4371533383188955\n",
            "Epoch 24, Loss: 1.4259785709478665\n",
            "Epoch 25, Loss: 1.40423893943772\n",
            "Epoch 26, Loss: 1.3962271004686575\n",
            "Epoch 27, Loss: 1.3774946932597538\n",
            "Epoch 28, Loss: 1.3667888645930668\n",
            "Epoch 29, Loss: 1.3552634406577595\n",
            "Epoch 30, Loss: 1.338362893942372\n",
            "Accuracy of the model on the 10000 test images: 62.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming CIFAR10Classifier is already defined and ready to be used\n",
        "\n",
        "# Define your CIFAR10Classifier model\n",
        "modelb = CIFAR10Classifier().to(device)\n",
        "\n",
        "# Criterion (Loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer - SGD with learning rate = 0.01 and weight decay = 0.0005\n",
        "optimizer = optim.SGD(modelb.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# CIFAR-10 Data Loaders\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 30  # You might adjust this based on observation\n",
        "for epoch in range(num_epochs):\n",
        "    modelb.train()  # Set model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward + backward + optimize\n",
        "        outputs = modelb(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Print statistics\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n",
        "\n",
        "# Don't forget to evaluate your model on the test set after training\n",
        "modelb.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Gradient computation is not needed for evaluation\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = modelb(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYuFaH-amk0q",
        "outputId": "7f9a67c0-f5ba-4f3c-9ee6-c9263b538c56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1, Loss: 2.2172538371342223\n",
            "Epoch 2, Loss: 2.0500300409238967\n",
            "Epoch 3, Loss: 1.9548271138344884\n",
            "Epoch 4, Loss: 1.8862769993979607\n",
            "Epoch 5, Loss: 1.8349451456228485\n",
            "Epoch 6, Loss: 1.7946608147352858\n",
            "Epoch 7, Loss: 1.7552768798435436\n",
            "Epoch 8, Loss: 1.7275069894083321\n",
            "Epoch 9, Loss: 1.7062956980427209\n",
            "Epoch 10, Loss: 1.6827622868520828\n",
            "Epoch 11, Loss: 1.6610377278474286\n",
            "Epoch 12, Loss: 1.649524820277758\n",
            "Epoch 13, Loss: 1.6251667161731769\n",
            "Epoch 14, Loss: 1.6177007185528651\n",
            "Epoch 15, Loss: 1.5925916966879765\n",
            "Epoch 16, Loss: 1.574739970362095\n",
            "Epoch 17, Loss: 1.549618603933193\n",
            "Epoch 18, Loss: 1.542361816786744\n",
            "Epoch 19, Loss: 1.5164294659024309\n",
            "Epoch 20, Loss: 1.49933549647441\n",
            "Epoch 21, Loss: 1.4879309342950202\n",
            "Epoch 22, Loss: 1.467726619042399\n",
            "Epoch 23, Loss: 1.4643865755147032\n",
            "Epoch 24, Loss: 1.441449738524454\n",
            "Epoch 25, Loss: 1.4274560534740652\n",
            "Epoch 26, Loss: 1.4079837039913363\n",
            "Epoch 27, Loss: 1.3966126135548058\n",
            "Epoch 28, Loss: 1.3851374674331196\n",
            "Epoch 29, Loss: 1.3735514990509015\n",
            "Epoch 30, Loss: 1.3586609334592015\n",
            "Accuracy of the model on the 10000 test images: 61.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming CIFAR10Classifier is defined within allowed adjustments\n",
        "modelb = CIFAR10Classifier().to(device)\n",
        "\n",
        "# Criterion (Loss function)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Using ADAM Optimizer\n",
        "optimizer = optim.Adam(modelb.parameters(), lr=0.001)\n",
        "\n",
        "# Enhanced Data Augmentation for Task 4\n",
        "transform_train_task4 = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Loading CIFAR-10 Data\n",
        "trainset_task4 = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train_task4)\n",
        "trainloader_task4 = DataLoader(trainset_task4, batch_size=128, shuffle=True)\n",
        "\n",
        "testset_task4 = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader_task4 = DataLoader(testset_task4, batch_size=100, shuffle=False)\n",
        "\n",
        "# Training Loop\n",
        "num_epochs = 50  # Increased epochs for more thorough training\n",
        "best_accuracy = 0  # Track the best testing accuracy\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    modelb.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in trainloader_task4:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = modelb(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss / len(trainloader_task4)}')\n",
        "\n",
        "    # Evaluation on the test set\n",
        "    modelb.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader_task4:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = modelb(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Test Accuracy after epoch {epoch+1}: {accuracy}%')\n",
        "\n",
        "    # Save the model if it has the best accuracy so far\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(modelb.state_dict(), 'best_model.pth')\n",
        "        print(f\"New best model saved with accuracy: {accuracy}%\")\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8_lUf7MIsvYO",
        "outputId": "e78bb44e-9afa-4feb-ba08-9f77e1dfe3af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'CIFAR10Classifier' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-36b10c2215c4>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Assuming CIFAR10Classifier is defined within allowed adjustments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodelb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10Classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Criterion (Loss function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CIFAR10Classifier' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class CIFAR10Classifier(nn.Module):\n",
        "    # Assuming this class is defined as per the basic architecture requirements\n",
        "    ...\n",
        "\n",
        "# Adjustments for Data Augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Keeping test transforms simple as per the basic requirements\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "# Data Loaders\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = DataLoader(testset, batch_size=100, shuffle=False)\n",
        "\n",
        "model = CIFAR10Classifier().to(device)\n",
        "\n",
        "# Using Adam with a learning rate scheduler\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training Loop with scheduler step\n",
        "...\n",
        "for epoch in range(num_epochs):\n",
        "    ...\n",
        "    scheduler.step()  # Adjust the learning rate based on the epoch\n"
      ],
      "metadata": {
        "id": "wTcCDAtLmvIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example placeholders for your metrics\n",
        "train_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "# After training, plot them\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(test_accuracies, label='Testing Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Testing Accuracy')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zFD34ZaRatKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Example data logged from your training process\n",
        "epochs = range(1, num_epochs + 1)\n",
        "training_loss = [...]  # Fill in with your logged training loss values\n",
        "training_accuracy = [...]  # Fill in with your logged training accuracy values\n",
        "test_accuracy = [...]  # Fill in with your logged test accuracy values\n",
        "\n",
        "# Plotting training loss\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, training_loss, label='Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# Plotting training and test accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
        "plt.plot(epochs, test_accuracy, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy Over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eoRbBSFZjcHA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}